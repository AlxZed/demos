{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model-deployment-with-streaming\"></a>\n",
    "\n",
    "\n",
    "Deploy a model with streaming information. The demo covers the use case of 1<sup>st</sup>-day churn.\n",
    "\n",
    "The importance of 1<sup>st</sup>-day churn prediction:\n",
    "- In some segments of the gaming industry, the average 1st day churn is as high as 70%.\n",
    "- Acquiring new customers is 5x&ndash;25x more expensive than retaining existing ones.\n",
    "- Reducing churn by just 5% can boost profitability by 75%.\n",
    "- Improving retention has a 2x&ndash;4x greater impact on growth than acquisition.\n",
    "- The probability of selling to an existing customer is 60%&ndash;70%, but only 5%&ndash;20% for a prospect.\n",
    "- Churn rate also informs metrics like customer lifetime value (LTV).\n",
    "\n",
    "This demo is comprised of several steps:\n",
    "\n",
    "![Model deployment Pipeline Real-time operational Pipeline](assets/model-deployment-pipeline.png)\n",
    "\n",
    "While this demo covers the use case of 1<sup>st</sup>-day churn, it is easy to replace the data, related features and training model and reuse the same workflow for different business cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These steps are covered by the following demo:\n",
    "\n",
    "- [**1. Data generator**](functions/data-generator.ipynb) â€” Generates events for the training and serving and Create an enrichment table (lookup values). \n",
    "- [**2. Event handler**](functions/event-handler.ipynb) - Receive data from the input. This is a common input stream for all the data. This way, one can easily replace the event source data (in this case we have a data generator) without affecting the rest of this flow. It also store all incoming data to parquet files.\n",
    "- [**3. Stream to features**](functions/stream-to-features.ipynb) - Enrich the stream using the enrichment table and Update aggregation features using the incoming event handler.\n",
    "- **4. Optional model training steps -**\n",
    " - [**4.1 Get Data Snapshot**](https://github.com/mlrun/functions/tree/master/describe) - Takes a snapshot of the feature table for training.\n",
    "  - [**4.2 Describe the Dataset**](functions/get-data-snapshot.ipynb) - Runs common analysis on the datasets and produces plots suche as histogram, feature importance, corollation and more.\n",
    "  - [**4.3 Training**](https://github.com/mlrun/functions/tree/master/sklearn_classifier) - Runing training with multiple classification models.\n",
    "  - [**4.4 Testing**](https://github.com/mlrun/functions/tree/master/test_classifier) - Testing the best performing model.\n",
    "- [**5. Serving**](https://github.com/mlrun/functions/tree/master/model_server) - Serve the model and process the data from the enriched stream and aggregation features.\n",
    "- [**6. Inference logger**](functions/event-handler.ipynb) - We use the same event handler function from above but only its capability to store incoming data to parquet files.\n",
    "\n",
    "This demo comes with a pre-trained model using the base features, enrichment data and derived features, calculated using the same generated data. You can retrain the model or train a new model by running the  **optional model training steps**. You will need to ensure enough data is collected via the streams to the data storage in order to train a new model.\n",
    "\n",
    "## About this demo\n",
    "\n",
    "### Input Data\n",
    "\n",
    "The data generator ([data-generator.ipynb](functions/-generator.ipynb)) creates the following events: `new_registration`, `new_purchases`, `new_bet` and `new_win` with the following data:\n",
    "\n",
    "| new_registration |   | new_purchases |   | new_bet    |   | new_win    |\n",
    "|------------------|---|---------------|---|------------|---|------------|\n",
    "| user_id          |   | user_id       |   | user_id    |   | user_id    |\n",
    "| event_type       |   | event_type    |   | event_type |   | event_type |\n",
    "| event_time       |   | event_time    |   | event_time |   | event_time |\n",
    "| name             |   | amount        |   | bet_amount |   | win_amount |\n",
    "| date_of_birth    |   |               |   |            |   |            |\n",
    "| street_address   |   |               |   |            |   |            |\n",
    "| city             |   |               |   |            |   |            |\n",
    "| country          |   |               |   |            |   |            |\n",
    "| postcode         |   |               |   |            |   |            |\n",
    "| affiliate_url    |   |               |   |            |   |            |\n",
    "| campaign         |   |               |   |            |   |            |\n",
    "\n",
    "Furthermore, `new_registration` includes a `label` column to indicate whether or not the user has churned (1 for churned and 0 for not)\n",
    "\n",
    "## Enrichment\n",
    "\n",
    "The same data generator ([data-generator.ipynb](functions/-generator.ipynb)) also creates the enrichment table which contains a lookup of postcode and returns a socioeconomic index (`socioeconomic_idx`).\n",
    "\n",
    "## Feature calculation\n",
    "\n",
    "During the feature calculation ([stream-to-features.ipynb](functions/stream-to-features.ipynb)), enriches the events using the enrichment table and calculates sum, mean, count and variance for the 3 amount fields (`amount`, `bet_amount` and `win_amount` for `new_purchases`, `new_bet` and `new_win` respectively). This results with the following list of fields:\n",
    "\n",
    "- purchase_sum\n",
    "- purchase_mean\n",
    "- purchase_count\n",
    "- purchase_var\n",
    "- bet_sum\n",
    "- bet_mean\n",
    "- bet_count\n",
    "- bet_var\n",
    "- win_sum\n",
    "- win_mean\n",
    "- win_count\n",
    "- win_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration below is shared across the notebooks. Change the values in this subsection if you would like different configuration settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projects in the platform are used to package multiple functions, workflows, and artifacts. Set here the project base name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_base_name = \"model-deployment-pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data in the platform is stored in user-defined data containers. This demo uses the predefined \"users\" container. For more information, see the platform's [data-containers](https://www.iguazio.com/docs/latest-release/data-layer/containers/) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = 'users'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data path where to store stream data and kv tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['V3IO_API'] = \n",
    "os.environ['V3IO_ACCESS_KEY'] = \n",
    "os.environ['V3IO_USERNAME'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv, path, getcwd\n",
    "\n",
    "v3io_username = getenv('V3IO_USERNAME')\n",
    "data_path = path.join(v3io_username, 'examples',project_base_name, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the different stream information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "web_api = getenv('V3IO_API')\n",
    "web_api_users = urljoin(web_api, container)\n",
    "stream_configs = {'generated-stream': {\n",
    "                        'path': path.join(data_path, 'generated-stream'),\n",
    "                        'shard_count': 8},\n",
    "                  'incoming-events-stream': {\n",
    "                        'path': path.join(data_path, 'incoming-events-stream'),\n",
    "                        'shard_count': 8\n",
    "                  },\n",
    "                  'serving-stream': {\n",
    "                        'path': path.join(data_path, 'serving-stream'),\n",
    "                        'shard_count': 8\n",
    "                  },\n",
    "                  'inference-stream': {\n",
    "                        'path': path.join(data_path, 'inference-stream'),\n",
    "                        'shard_count': 8\n",
    "                  }\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we stream data, we associate the records with a specific partition key to ensure that similar records are assigned to the same shard. For more information, see the [stream sharding and partitioning description](https://www.iguazio.com/docs/latest-release/data-layer/stream/#stream-sharding-and-partitioning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_attr = \"user_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target path to store the raw data and the inference data as parquet files.\n",
    "The parquet files will be written via file mount, hence we configure the path to start with '/User' which will be mounted to our home dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_parquet_target_path = path.join(data_path.replace(v3io_username, '/User'),  'events-pq')\n",
    "inference_parquet_target_path = path.join(data_path.replace(v3io_username, '/User'),  'inference-pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target path to store the enrichment table (a key-value table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_table_path = path.join(data_path, 'enrichment-table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target path to store the calculated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table_path = path.join(data_path, 'feature-table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['socioeconomic_idx','purchase_sum','purchase_mean','purchase_count',\n",
    "                'purchase_var','bet_sum','bet_mean','bet_count',\n",
    "                'bet_var','win_sum','win_mean','win_count','win_var']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create V3IO Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataplane client you can manipulate data in the platform's multi-model data layer, including:\n",
    "* Objects\n",
    "* Key-values (NoSQL)\n",
    "* Streams\n",
    "* Containers\n",
    "\n",
    "Under the hood, the client connects through the platform's web API (https://www.iguazio.com/docs/latest-release/data-layer/reference/web-apis/) and wraps each low level API with an interface. Calls are blocking, but you can use the batching interface to send multiple requests in parallel for greater performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import v3io.dataplane\n",
    "v3io_client = v3io.dataplane.Client(endpoint=web_api,\n",
    "                                    access_key=getenv('V3IO_ACCESS_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage Streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete all streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanup previous streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete Stream call for stream generated-stream returned with status 204, and content: \n",
      "Delete Stream call for stream incoming-events-stream returned with status 204, and content: \n",
      "Delete Stream call for stream serving-stream returned with status 204, and content: \n",
      "Delete Stream call for stream inference-stream returned with status 204, and content: \n"
     ]
    }
   ],
   "source": [
    "for stream_name, stream_config in stream_configs.items():\n",
    "    resp = v3io_client.stream.delete(container=container, stream_path=stream_config['path'], \n",
    "                                     raise_for_status=v3io.dataplane.RaiseForStatus.never)\n",
    "    print(f'Delete Stream call for stream {stream_name} returned with status {resp.status_code}, and content: {resp.body.decode(\"utf-8\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create all streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admin/examples/model-deployment-pipeline/data/generated-stream\n",
      "Create Stream call for stream generated-stream returned with status 204, and content: \n",
      "admin/examples/model-deployment-pipeline/data/incoming-events-stream\n",
      "Create Stream call for stream incoming-events-stream returned with status 204, and content: \n",
      "admin/examples/model-deployment-pipeline/data/serving-stream\n",
      "Create Stream call for stream serving-stream returned with status 204, and content: \n",
      "admin/examples/model-deployment-pipeline/data/inference-stream\n",
      "Create Stream call for stream inference-stream returned with status 204, and content: \n"
     ]
    }
   ],
   "source": [
    "for stream_name, stream_config in stream_configs.items():\n",
    "    print(stream_config['path'])\n",
    "    resp = v3io_client.stream.create(container=container,\n",
    "                                     stream_path=stream_config['path'],\n",
    "                                     shard_count=stream_config['shard_count'],\n",
    "                                     raise_for_status=v3io.dataplane.RaiseForStatus.never)\n",
    "    print(f'Create Stream call for stream {stream_name} returned with status {resp.status_code}, and content: {resp.body.decode(\"utf-8\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up MLRun Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projects are created by using the `new_project` MLRun method, which receives the following parameters:\n",
    "\n",
    "- **`name`** (Required) &mdash; the project name.\n",
    "- **`context`** &mdash; the path to a local project directory (the project's context directory).\n",
    "  The project directory contains a project-configuration file (default: **project.yaml**), which defines the project, and additional generated Python code.\n",
    "  The project file is created when you save your project (using the `save` MLRun project method), as demonstrated in Step 6.\n",
    "- **`functions`** &mdash; a list of functions objects or links to function code or objects.\n",
    "- **`init_git`** &mdash; set to `True` to perform Git initialization of the project directory (`context`).\n",
    "  > **Note:** It's customary to store project code and definitions in a Git repository.\n",
    "\n",
    "Projects are visible in the MLRun dashboard only after they're saved to the MLRun database, which happens whenever you run code for a project.\n",
    "\n",
    "The following code creates a project using the `PROJECT_BASE_NAME`, concatenated with your current running username in the platform (**&lt;V3IO_USERNAME&gt;**), and sets the project directory to a **conf** directory in the current demo directory (**/User/demos/model-deployment-with-streaming/conf**).\n",
    "\n",
    "> **Note:** Platform projects are shared among all users of the parent tenant, to facilitate collaboration. Therefore,\n",
    ">\n",
    "> - Synchronize your projects execution with other users on your platform cluster, as needed, or use unique project names to avoid conflicts.\n",
    ">   You can easily change the default project name for this tutorial by changing the definition of the `PROJECT_BASE_NAME` variable, defined in the beginning of the notebook.\n",
    "> - Don't include in your project proprietary information that you don't want to expose to other users.\n",
    ">   Note that while projects are a useful tool, you can easily develop and run code in the platform without using projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path: /home/jovyan/data/demos/model-deployment-pipeline/conf\n",
      "Project name: model-deployment-pipeline-admin\n"
     ]
    }
   ],
   "source": [
    "from mlrun import new_project\n",
    "\n",
    "project_name = '-'.join(filter(None, [project_base_name, getenv('V3IO_USERNAME', None)]))\n",
    "project_path = path.abspath('conf')\n",
    "project = new_project(project_name, project_path, init_git=True)\n",
    "\n",
    "print(f'Project path: {project_path}\\nProject name: {project_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MLRun](https://github.com/mlrun/mlrun) is a generic and convenient mechanism for data scientists and software developers to describe and run tasks related to machine learning in various, scalable runtime environments and ML pipelines while automatically tracking executed code, metadata, inputs, and outputs.\n",
    "MLRun integrates with the Nuclio serverless framework and with the Kubeflow Pipelines framework for running ML pipelines.\n",
    "The demo uses MLRun to create a project, run Nuclio serverless functions, as well as run the model training.\n",
    "Before running your code, you need to set some MLRun configurations:\n",
    "\n",
    "- <a id=\"gs-mlrun-config-artifcats-path\"></a>**Artifacts path** &mdash; the location for storing versioned data artifacts (such as files, objects, data sets, and models) that are produced or consumed by functions, runs, and workflows.\n",
    "  The path can be defined either as a local directory path or as a URL (of the format `s3://*`, `v3io://*`, etc.).\n",
    "  You can set the artifacts path either by defining an `MLRUN_ARTIFACT_PATH` environment variable (which applies globally throughout the current environment) or as part of the MLRun configuration.\n",
    " \n",
    "  If the target directory doesn't exist, MLRun creates it.\n",
    "  You can use the notation `{{run.uid}}` in the path to signify the current run ID.\n",
    "  For pipelines, you can use the notation `{{workflow.uid}}` to signify the workflow ID.\n",
    "  This allows you to create a unique artifacts directory for each executed job or workflow.\n",
    "\n",
    "  After you run an MLRun job, the artifacts directory might contain one or more of the following directories:\n",
    " \n",
    "  - **plots** &mdash; a directory for storing images, figures, and plotlines.\n",
    "  - **models** &mdash; a directory for storing all trained models.\n",
    "  - **data** &mdash; a directory for storing any other type of data artifact, such as data sets.\n",
    "\n",
    "The following code sets the artifacts path to a **artifacts** directory within the tutorial directory (**/User/demos/model-deployment-with-streaming/artifacts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts path: /home/jovyan/data/demos/model-deployment-pipeline/artifacts\n",
      "MLRun DB path: http://mlrun-api:8080\n"
     ]
    }
   ],
   "source": [
    "from mlrun import mlconf\n",
    "\n",
    "# Target location for storing pipeline artifacts\n",
    "project.artifact_path = path.abspath('artifacts')\n",
    "# MLRun DB path or API service URL\n",
    "mlconf.dbpath = mlconf.dbpath or 'http://mlrun-api:8080'\n",
    "\n",
    "print(f'Artifacts path: {project.artifact_path}\\nMLRun DB path: {mlconf.dbpath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set project's functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7f4bf902dd00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import mount_v3io, code_to_function, NewTask\n",
    "import nuclio\n",
    "\n",
    "data_generator = code_to_function(name='data-generator', handler='main', kind='job', filename='functions/data-generator.ipynb')\n",
    "project.set_function(data_generator)\n",
    "\n",
    "# set parameters and  environment variables\n",
    "v3io_envs = {'V3IO_API': getenv('V3IO_API'),\n",
    "        'V3IO_ACCESS_KEY': getenv('V3IO_ACCESS_KEY')}\n",
    "dg_params = {'container': container,\n",
    "         'output_stream_path': stream_configs['generated-stream']['path'],\n",
    "         'enrichment_table_path': enrichment_table_path}\n",
    "\n",
    "project.func('data-generator').set_envs(v3io_envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-05-07 13:06:53,394 [info] starting remote build, image: .gshaham/func-model-deployment-pipeline-admin-data-generator:latest\n",
      "E0507 13:06:55.700310       1 aws_credentials.go:77] while getting AWS credentials NoCredentialProviders: no valid providers in chain. Deprecated.\n",
      "\tFor verbose messaging see aws.Config.CredentialsChainVerboseErrors\n",
      "\u001b[36mINFO\u001b[0m[0003] Retrieving image manifest mlrun/mlrun:0.6.3-rc12 \n",
      "\u001b[36mINFO\u001b[0m[0005] Retrieving image manifest mlrun/mlrun:0.6.3-rc12 \n",
      "\u001b[36mINFO\u001b[0m[0008] Built cross stage deps: map[]                \n",
      "\u001b[36mINFO\u001b[0m[0008] Retrieving image manifest mlrun/mlrun:0.6.3-rc12 \n",
      "\u001b[36mINFO\u001b[0m[0011] Retrieving image manifest mlrun/mlrun:0.6.3-rc12 \n",
      "\u001b[36mINFO\u001b[0m[0014] Executing 0 build triggers                   \n",
      "\u001b[36mINFO\u001b[0m[0014] Unpacking rootfs as cmd RUN python -m pip install faker requires it. \n",
      "\u001b[36mINFO\u001b[0m[0122] RUN python -m pip install faker              \n",
      "\u001b[36mINFO\u001b[0m[0122] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0126] cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0126] args: [-c python -m pip install faker]       \n",
      "\u001b[36mINFO\u001b[0m[0126] Running: [/bin/sh -c python -m pip install faker] \n",
      "Collecting faker\n",
      "  Downloading Faker-8.1.2-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.7/site-packages (from faker) (2.8.1)\n",
      "Collecting text-unidecode==1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Installing collected packages: text-unidecode, faker\n",
      "Successfully installed faker-8.1.2 text-unidecode-1.3\n",
      "WARNING: You are using pip version 20.2.4; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[36mINFO\u001b[0m[0132] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0133] RUN pip install \"mlrun[complete]==0.6.3-rc12\" \n",
      "\u001b[36mINFO\u001b[0m[0133] cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0133] args: [-c pip install \"mlrun[complete]==0.6.3-rc12\"] \n",
      "\u001b[36mINFO\u001b[0m[0133] Running: [/bin/sh -c pip install \"mlrun[complete]==0.6.3-rc12\"] \n",
      "Requirement already satisfied: mlrun[complete]==0.6.3-rc12 in /usr/local/lib/python3.7/site-packages (0.6.3rc12)\n",
      "Requirement already satisfied: sqlalchemy~=1.3 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (1.4.14)\n",
      "Requirement already satisfied: nest-asyncio~=1.0 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (1.5.1)\n",
      "Requirement already satisfied: click~=7.0 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (7.1.2)\n",
      "Requirement already satisfied: dask~=2.12 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (2.30.0)\n",
      "Requirement already satisfied: storey~=0.4.9; python_version >= \"3.7\" in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (0.4.9)\n",
      "Requirement already satisfied: requests~=2.22 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (2.25.1)\n",
      "Requirement already satisfied: kubernetes~=11.0 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (11.0.0)\n",
      "Requirement already satisfied: pydantic~=1.5 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (1.8.1)\n",
      "Requirement already satisfied: humanfriendly~=8.2 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (8.2)\n",
      "Requirement already satisfied: semver~=2.13 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (2.13.0)\n",
      "Requirement already satisfied: chardet<4.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (3.0.4)\n",
      "Requirement already satisfied: ipython<7.17,>=5.5 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (7.16.1)\n",
      "Requirement already satisfied: cryptography~=3.3.2 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (3.3.2)\n",
      "Requirement already satisfied: kfp~=1.0.1 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (1.0.4)\n",
      "Requirement already satisfied: GitPython~=3.0 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (3.1.14)\n",
      "Requirement already satisfied: alembic<1.6.0,~=1.4 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (1.5.8)\n",
      "Requirement already satisfied: distributed<3,>=2.23 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (2.30.1)\n",
      "Requirement already satisfied: mergedeep~=1.3 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (1.3.4)\n",
      "Requirement already satisfied: v3iofs~=0.1.5 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (0.1.6)\n",
      "Requirement already satisfied: pyarrow~=1.0 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (1.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (1.26.4)\n",
      "Requirement already satisfied: nuclio-jupyter~=0.8.12 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (0.8.12)\n",
      "Requirement already satisfied: numpy<1.20.0,>=1.16.5 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (1.19.5)\n",
      "Requirement already satisfied: fastapi~=0.62.0 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (0.62.0)\n",
      "Requirement already satisfied: orjson<3.4,>=3 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (3.3.1)\n",
      "Requirement already satisfied: v3io-frames~=0.8.5 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (0.8.14)\n",
      "Requirement already satisfied: fsspec~=0.9.0 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (0.9.0)\n",
      "Requirement already satisfied: tabulate<=0.8.3,>=0.8.0 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (0.8.3)\n",
      "Requirement already satisfied: v3io~=0.5.0 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (0.5.7)\n",
      "Requirement already satisfied: pandas~=1.2; python_version >= \"3.7\" in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (1.2.4)\n",
      "Requirement already satisfied: aiohttp~=3.6 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (3.7.4.post0)\n",
      "Requirement already satisfied: pyyaml~=5.1 in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (5.4.1)\n",
      "Requirement already satisfied: azure-storage-blob<12.7.0,~=12.0; extra == \"complete\" in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (12.6.0)\n",
      "Requirement already satisfied: s3fs~=0.5.0; extra == \"complete\" in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (0.5.2)\n",
      "Requirement already satisfied: azure-keyvault-secrets~=4.2; extra == \"complete\" in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (4.2.0)\n",
      "Requirement already satisfied: botocore<1.20.50,>=1.20.49; extra == \"complete\" in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (1.20.49)\n",
      "Requirement already satisfied: boto3<1.17.50,~=1.9; extra == \"complete\" in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (1.17.49)\n",
      "Requirement already satisfied: adlfs~=0.7.1; extra == \"complete\" in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (0.7.4)\n",
      "Requirement already satisfied: azure-identity~=1.5; extra == \"complete\" in /usr/local/lib/python3.7/site-packages (from mlrun[complete]==0.6.3-rc12) (1.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/site-packages (from sqlalchemy~=1.3->mlrun[complete]==0.6.3-rc12) (1.1.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/site-packages (from sqlalchemy~=1.3->mlrun[complete]==0.6.3-rc12) (4.0.1)\n",
      "Requirement already satisfied: grpcio-tools~=1.30.0 in /usr/local/lib/python3.7/site-packages (from storey~=0.4.9; python_version >= \"3.7\"->mlrun[complete]==0.6.3-rc12) (1.30.0)\n",
      "Requirement already satisfied: grpcio~=1.30.0 in /usr/local/lib/python3.7/site-packages (from storey~=0.4.9; python_version >= \"3.7\"->mlrun[complete]==0.6.3-rc12) (1.30.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests~=2.22->mlrun[complete]==0.6.3-rc12) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests~=2.22->mlrun[complete]==0.6.3-rc12) (2.10)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/site-packages (from kubernetes~=11.0->mlrun[complete]==0.6.3-rc12) (2.8.1)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.7/site-packages (from kubernetes~=11.0->mlrun[complete]==0.6.3-rc12) (53.0.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.7/site-packages (from kubernetes~=11.0->mlrun[complete]==0.6.3-rc12) (1.3.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.7/site-packages (from kubernetes~=11.0->mlrun[complete]==0.6.3-rc12) (0.59.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/site-packages (from kubernetes~=11.0->mlrun[complete]==0.6.3-rc12) (1.16.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.7/site-packages (from kubernetes~=11.0->mlrun[complete]==0.6.3-rc12) (1.30.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/site-packages (from pydantic~=1.5->mlrun[complete]==0.6.3-rc12) (3.10.0.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/site-packages (from ipython<7.17,>=5.5->mlrun[complete]==0.6.3-rc12) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/site-packages (from ipython<7.17,>=5.5->mlrun[complete]==0.6.3-rc12) (0.18.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/site-packages (from ipython<7.17,>=5.5->mlrun[complete]==0.6.3-rc12) (5.0.7)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from ipython<7.17,>=5.5->mlrun[complete]==0.6.3-rc12) (3.0.18)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/site-packages (from ipython<7.17,>=5.5->mlrun[complete]==0.6.3-rc12) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/site-packages (from ipython<7.17,>=5.5->mlrun[complete]==0.6.3-rc12) (5.0.5)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/site-packages (from ipython<7.17,>=5.5->mlrun[complete]==0.6.3-rc12) (2.9.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/site-packages (from ipython<7.17,>=5.5->mlrun[complete]==0.6.3-rc12) (0.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/site-packages (from cryptography~=3.3.2->mlrun[complete]==0.6.3-rc12) (1.14.5)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/site-packages (from kfp~=1.0.1->mlrun[complete]==0.6.3-rc12) (1.6.0)\n",
      "Requirement already satisfied: strip-hints in /usr/local/lib/python3.7/site-packages (from kfp~=1.0.1->mlrun[complete]==0.6.3-rc12) (0.1.9)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=0.2.5 in /usr/local/lib/python3.7/site-packages (from kfp~=1.0.1->mlrun[complete]==0.6.3-rc12) (1.5.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.7/site-packages (from kfp~=1.0.1->mlrun[complete]==0.6.3-rc12) (0.9.1)\n",
      "Requirement already satisfied: google-cloud-storage>=1.13.0 in /usr/local/lib/python3.7/site-packages (from kfp~=1.0.1->mlrun[complete]==0.6.3-rc12) (1.38.0)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/site-packages (from kfp~=1.0.1->mlrun[complete]==0.6.3-rc12) (3.2.0)\n",
      "Requirement already satisfied: Deprecated in /usr/local/lib/python3.7/site-packages (from kfp~=1.0.1->mlrun[complete]==0.6.3-rc12) (1.2.12)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/site-packages (from GitPython~=3.0->mlrun[complete]==0.6.3-rc12) (4.0.7)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.7/site-packages (from alembic<1.6.0,~=1.4->mlrun[complete]==0.6.3-rc12) (1.1.4)\n",
      "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/site-packages (from alembic<1.6.0,~=1.4->mlrun[complete]==0.6.3-rc12) (1.0.4)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/site-packages (from distributed<3,>=2.23->mlrun[complete]==0.6.3-rc12) (1.7.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/site-packages (from distributed<3,>=2.23->mlrun[complete]==0.6.3-rc12) (2.0.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/site-packages (from distributed<3,>=2.23->mlrun[complete]==0.6.3-rc12) (1.0.2)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/site-packages (from distributed<3,>=2.23->mlrun[complete]==0.6.3-rc12) (2.3.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/site-packages (from distributed<3,>=2.23->mlrun[complete]==0.6.3-rc12) (0.11.1)\n",
      "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/site-packages (from distributed<3,>=2.23->mlrun[complete]==0.6.3-rc12) (5.8.0)\n",
      "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /usr/local/lib/python3.7/site-packages (from distributed<3,>=2.23->mlrun[complete]==0.6.3-rc12) (6.1)\n",
      "Requirement already satisfied: notebook>=5.2.0 in /usr/local/lib/python3.7/site-packages (from nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (6.3.0)\n",
      "Requirement already satisfied: nbconvert>=5.4 in /usr/local/lib/python3.7/site-packages (from nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (6.0.7)\n",
      "Requirement already satisfied: starlette==0.13.6 in /usr/local/lib/python3.7/site-packages (from fastapi~=0.62.0->mlrun[complete]==0.6.3-rc12) (0.13.6)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.5.3 in /usr/local/lib/python3.7/site-packages (from v3io-frames~=0.8.5->mlrun[complete]==0.6.3-rc12) (1.53.0)\n",
      "Requirement already satisfied: ujson>=3.0.0 in /usr/local/lib/python3.7/site-packages (from v3io~=0.5.0->mlrun[complete]==0.6.3-rc12) (4.0.2)\n",
      "Requirement already satisfied: future>=0.18.2 in /usr/local/lib/python3.7/site-packages (from v3io~=0.5.0->mlrun[complete]==0.6.3-rc12) (0.18.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas~=1.2; python_version >= \"3.7\"->mlrun[complete]==0.6.3-rc12) (2021.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/site-packages (from aiohttp~=3.6->mlrun[complete]==0.6.3-rc12) (5.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/site-packages (from aiohttp~=3.6->mlrun[complete]==0.6.3-rc12) (1.6.3)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/site-packages (from aiohttp~=3.6->mlrun[complete]==0.6.3-rc12) (3.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/site-packages (from aiohttp~=3.6->mlrun[complete]==0.6.3-rc12) (21.1.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.9.0 in /usr/local/lib/python3.7/site-packages (from azure-storage-blob<12.7.0,~=12.0; extra == \"complete\"->mlrun[complete]==0.6.3-rc12) (1.13.0)\n",
      "Requirement already satisfied: msrest>=0.6.10 in /usr/local/lib/python3.7/site-packages (from azure-storage-blob<12.7.0,~=12.0; extra == \"complete\"->mlrun[complete]==0.6.3-rc12) (0.6.21)\n",
      "Requirement already satisfied: aiobotocore>=1.0.1 in /usr/local/lib/python3.7/site-packages (from s3fs~=0.5.0; extra == \"complete\"->mlrun[complete]==0.6.3-rc12) (1.3.0)\n",
      "Requirement already satisfied: azure-common~=1.1 in /usr/local/lib/python3.7/site-packages (from azure-keyvault-secrets~=4.2; extra == \"complete\"->mlrun[complete]==0.6.3-rc12) (1.1.27)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from botocore<1.20.50,>=1.20.49; extra == \"complete\"->mlrun[complete]==0.6.3-rc12) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/site-packages (from boto3<1.17.50,~=1.9; extra == \"complete\"->mlrun[complete]==0.6.3-rc12) (0.3.7)\n",
      "Requirement already satisfied: azure-datalake-store<0.1,>=0.0.46 in /usr/local/lib/python3.7/site-packages (from adlfs~=0.7.1; extra == \"complete\"->mlrun[complete]==0.6.3-rc12) (0.0.52)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.6.0 in /usr/local/lib/python3.7/site-packages (from azure-identity~=1.5; extra == \"complete\"->mlrun[complete]==0.6.3-rc12) (1.11.0)\n",
      "Requirement already satisfied: msal-extensions~=0.3.0 in /usr/local/lib/python3.7/site-packages (from azure-identity~=1.5; extra == \"complete\"->mlrun[complete]==0.6.3-rc12) (0.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy~=1.3->mlrun[complete]==0.6.3-rc12) (3.4.1)\n",
      "Requirement already satisfied: protobuf>=3.5.0.post1 in /usr/local/lib/python3.7/site-packages (from grpcio-tools~=1.30.0->storey~=0.4.9; python_version >= \"3.7\"->mlrun[complete]==0.6.3-rc12) (3.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib->kubernetes~=11.0->mlrun[complete]==0.6.3-rc12) (3.1.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/site-packages (from google-auth>=1.0.1->kubernetes~=11.0->mlrun[complete]==0.6.3-rc12) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth>=1.0.1->kubernetes~=11.0->mlrun[complete]==0.6.3-rc12) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth>=1.0.1->kubernetes~=11.0->mlrun[complete]==0.6.3-rc12) (4.2.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/site-packages (from jedi>=0.10->ipython<7.17,>=5.5->mlrun[complete]==0.6.3-rc12) (0.8.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<7.17,>=5.5->mlrun[complete]==0.6.3-rc12) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython<7.17,>=5.5->mlrun[complete]==0.6.3-rc12) (0.7.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/site-packages (from traitlets>=4.2->ipython<7.17,>=5.5->mlrun[complete]==0.6.3-rc12) (0.2.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/site-packages (from cffi>=1.12->cryptography~=3.3.2->mlrun[complete]==0.6.3-rc12) (2.20)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.7/site-packages (from strip-hints->kfp~=1.0.1->mlrun[complete]==0.6.3-rc12) (0.36.2)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /usr/local/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp~=1.0.1->mlrun[complete]==0.6.3-rc12) (1.6.0)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=1.2.0 in /usr/local/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp~=1.0.1->mlrun[complete]==0.6.3-rc12) (1.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp~=1.0.1->mlrun[complete]==0.6.3-rc12) (0.17.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/site-packages (from Deprecated->kfp~=1.0.1->mlrun[complete]==0.6.3-rc12) (1.12.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython~=3.0->mlrun[complete]==0.6.3-rc12) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/site-packages (from Mako->alembic<1.6.0,~=1.4->mlrun[complete]==0.6.3-rc12) (1.1.1)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/site-packages (from zict>=0.1.3->distributed<3,>=2.23->mlrun[complete]==0.6.3-rc12) (1.0.1)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/site-packages (from notebook>=5.2.0->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (5.5.4)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/site-packages (from notebook>=5.2.0->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (0.10.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/site-packages (from notebook>=5.2.0->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (22.0.3)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /usr/local/lib/python3.7/site-packages (from notebook>=5.2.0->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (6.1.12)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.7/site-packages (from notebook>=5.2.0->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/site-packages (from notebook>=5.2.0->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (0.9.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/site-packages (from notebook>=5.2.0->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (2.11.3)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/site-packages (from notebook>=5.2.0->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (20.1.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.7/site-packages (from notebook>=5.2.0->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (4.7.1)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/site-packages (from notebook>=5.2.0->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (5.1.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/site-packages (from nbconvert>=5.4->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/site-packages (from nbconvert>=5.4->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (0.5.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/site-packages (from nbconvert>=5.4->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (1.4.3)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/site-packages (from nbconvert>=5.4->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (0.4.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.7/site-packages (from nbconvert>=5.4->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (0.1.2)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/site-packages (from nbconvert>=5.4->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (3.3.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/site-packages (from nbconvert>=5.4->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/site-packages (from nbconvert>=5.4->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (0.3)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.7/site-packages (from msrest>=0.6.10->azure-storage-blob<12.7.0,~=12.0; extra == \"complete\"->mlrun[complete]==0.6.3-rc12) (0.6.0)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /usr/local/lib/python3.7/site-packages (from aiobotocore>=1.0.1->s3fs~=0.5.0; extra == \"complete\"->mlrun[complete]==0.6.3-rc12) (0.7.1)\n",
      "Requirement already satisfied: adal>=0.4.2 in /usr/local/lib/python3.7/site-packages (from azure-datalake-store<0.1,>=0.0.46->adlfs~=0.7.1; extra == \"complete\"->mlrun[complete]==0.6.3-rc12) (1.2.7)\n",
      "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /usr/local/lib/python3.7/site-packages (from msal<2.0.0,>=1.6.0->azure-identity~=1.5; extra == \"complete\"->mlrun[complete]==0.6.3-rc12) (2.1.0)\n",
      "Requirement already satisfied: portalocker~=1.0; platform_system != \"Windows\" in /usr/local/lib/python3.7/site-packages (from msal-extensions~=0.3.0->azure-identity~=1.5; extra == \"complete\"->mlrun[complete]==0.6.3-rc12) (1.7.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth>=1.0.1->kubernetes~=11.0->mlrun[complete]==0.6.3-rc12) (0.4.8)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.21.0 in /usr/local/lib/python3.7/site-packages (from google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp~=1.0.1->mlrun[complete]==0.6.3-rc12) (1.26.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\" in /usr/local/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp~=1.0.1->mlrun[complete]==0.6.3-rc12) (1.1.2)\n",
      "Requirement already satisfied: async-generator in /usr/local/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert>=5.4->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (1.10)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from bleach->nbconvert>=5.4->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (20.9)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/site-packages (from bleach->nbconvert>=5.4->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging->bleach->nbconvert>=5.4->nuclio-jupyter~=0.8.12->mlrun[complete]==0.6.3-rc12) (2.4.7)\n",
      "WARNING: You are using pip version 20.2.4; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[36mINFO\u001b[0m[0134] Taking snapshot of full filesystem...        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the image\n",
    "project.func('data-generator').deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-05-07 18:58:38,234 [info] starting run data-generator-main uid=332646d2398640169535b63eb00e5047 DB=http://mlrun-api:8080\n",
      "> 2021-05-07 18:58:38,300 [info] Job is running in the background, pod: data-generator-main-hvb48\n",
      "2021-05-07 19:08:51,936 [warning] Unhandled exception while sending request: {'e': <class 'socket.gaierror'>}\n",
      "> 2021-05-07 19:08:52,000 [error] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/v3io/dataplane/batch.py\", line 81, in wait\n",
      "    return self._wait(raise_for_status)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/v3io/dataplane/batch.py\", line 121, in _wait\n",
      "    transport_state=inflight_request.transport)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/v3io/dataplane/transport/httpclient.py\", line 64, in send_request\n",
      "    return self._send_request_on_connection(request, connection_idx)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/v3io/dataplane/transport/httpclient.py\", line 143, in _send_request_on_connection\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.7/site-packages/v3io/dataplane/transport/httpclient.py\", line 133, in _send_request_on_connection\n",
      "    connection.request(request.method, path, request.body, request.headers)\n",
      "  File \"/usr/local/lib/python3.7/http/client.py\", line 1277, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/local/lib/python3.7/http/client.py\", line 1323, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/local/lib/python3.7/http/client.py\", line 1272, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/local/lib/python3.7/http/client.py\", line 1032, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/lib/python3.7/http/client.py\", line 972, in send\n",
      "    self.connect()\n",
      "  File \"/usr/local/lib/python3.7/http/client.py\", line 1439, in connect\n",
      "    super().connect()\n",
      "  File \"/usr/local/lib/python3.7/http/client.py\", line 944, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"/usr/local/lib/python3.7/socket.py\", line 707, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "  File \"/usr/local/lib/python3.7/socket.py\", line 752, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -5] No address associated with hostname\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlrun/runtimes/local.py\", line 314, in exec_from_params\n",
      "    val = handler(*args_list)\n",
      "  File \"main.py\", line 151, in main\n",
      "    table_resps = create_enrichment_table(v3io_client, container, enrichment_table_path)\n",
      "  File \"main.py\", line 138, in create_enrichment_table\n",
      "    return v3io_client.batch.wait()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/v3io/dataplane/batch.py\", line 87, in wait\n",
      "    self._transport.restart()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/v3io/dataplane/transport/httpclient.py\", line 48, in restart\n",
      "    self._ssl_context)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/v3io/dataplane/transport/httpclient.py\", line 163, in _create_connections\n",
      "    connection.connect()\n",
      "  File \"/usr/local/lib/python3.7/http/client.py\", line 1439, in connect\n",
      "    super().connect()\n",
      "  File \"/usr/local/lib/python3.7/http/client.py\", line 944, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"/usr/local/lib/python3.7/socket.py\", line 707, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "  File \"/usr/local/lib/python3.7/socket.py\", line 752, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno -5] No address associated with hostname\n",
      "\n",
      "> 2021-05-07 19:08:52,030 [error] exec error - [Errno -5] No address associated with hostname\n",
      "[Errno -5] No address associated with hostname\n",
      "> 2021-05-07 19:08:52,044 [info] run executed, status=error\n",
      "runtime error: [Errno -5] No address associated with hostname\n",
      "final state: error\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dictlist {\n",
       "  background-color: #4EC64B;\n",
       "  text-align: center;\n",
       "  margin: 4px;\n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer;\n",
       "  background-color: #4EC64B;\n",
       "  text-align: left;\n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #4EC64B;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "\n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "\n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }\n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "\n",
       "\n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>model-deployment-pipeline-admin</td>\n",
       "      <td><div title=\"332646d2398640169535b63eb00e5047\"><a href=\"http://localhost:30060/projects/model-deployment-pipeline-admin/jobs/monitor/332646d2398640169535b63eb00e5047/overview\" target=\"_blank\" >...b00e5047</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>May 07 18:58:47</td>\n",
       "      <td><div style=\"color: red;\" title=\"[Errno -5] No address associated with hostname\">error</div></td>\n",
       "      <td>data-generator-main</td>\n",
       "      <td><div class=\"dictlist\">v3io_user=admin</div><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=admin</div><div class=\"dictlist\">host=data-generator-main-hvb48</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">container=users</div><div class=\"dictlist\">output_stream_path=admin/examples/model-deployment-pipeline/data/generated-stream</div><div class=\"dictlist\">enrichment_table_path=admin/examples/model-deployment-pipeline/data/enrichment-table</div></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"resulte39b40f5-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"resulte39b40f5-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"resulte39b40f5\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"resulte39b40f5-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run 332646d2398640169535b63eb00e5047 --project model-deployment-pipeline-admin , !mlrun logs 332646d2398640169535b63eb00e5047 --project model-deployment-pipeline-admin\n",
      "> 2021-05-07 19:09:00,254 [info] run executed, status=error\n",
      "runtime error: [Errno -5] No address associated with hostname\n"
     ]
    },
    {
     "ename": "RunError",
     "evalue": "[Errno -5] No address associated with hostname",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRunError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d7220dd7bf0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Run the job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data-generator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/mlrun/runtimes/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, runspec, handler, name, project, params, inputs, out_path, workdir, artifact_path, watch, schedule, hyperparams, hyper_param_options, verbose, scrape_metrics, local, local_code_path)\u001b[0m\n\u001b[1;32m    426\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m                 )\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_run_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_remote\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_api_server\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/mlrun/runtimes/base.py\u001b[0m in \u001b[0;36m_wrap_run_result\u001b[0;34m(self, result, runspec, schedule, err)\u001b[0m\n\u001b[1;32m    502\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_remote\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"runtime error: {run.status.error}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRunError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRunError\u001b[0m: [Errno -5] No address associated with hostname"
     ]
    }
   ],
   "source": [
    "#Run the job\n",
    "project.func('data-generator').run(params=dg_params, artifact_path=project.artifact_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_handler = code_to_function(name='event-handler', handler='handler', kind='nuclio', filename='functions/event-handler.ipynb')\n",
    "project.set_function(event_handler)\n",
    "\n",
    "eh_envs = {'PARQUET_SINK_FLAG': 'true',\n",
    "           'STREAM_SINK_FLAG': 'true',\n",
    "           'PARQUET_TARGET_PATH' : raw_parquet_target_path,\n",
    "           'PARQUET_BATCH_SIZE': 8192,\n",
    "           'TS_KEY': 'event_time',\n",
    "           'TS_FORMAT': '%Y-%m-%d %H:%M:%S.%f',\n",
    "           'CONTAINER': container,\n",
    "           'OUTPUT_STREAM_PATH': stream_configs['incoming-events-stream']['path'],\n",
    "           'PARTITION_ATTR': partition_attr}\n",
    "\n",
    "project.func('event-handler').set_envs({**v3io_envs, **eh_envs})\n",
    "project.func('event-handler').apply(mount_v3io())\n",
    "\n",
    "generated_stream = '/'.join(s.strip('/') for s in [web_api_users, stream_configs['generated-stream']['path']]) + '@eh'\n",
    "project.func('event-handler').add_trigger('serving_stream',\n",
    "                                           nuclio.triggers.V3IOStreamTrigger(url=generated_stream,\n",
    "                                                                             maxWorkers=stream_configs['generated-stream']['shard_count']+2,\n",
    "                                                                             seekTo='earliest'))\n",
    "\n",
    "project.func('event-handler').spec.replicas=1\n",
    "project.func('event-handler').deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stream to Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_to_features = code_to_function(name='stream-to-features', handler='handler', kind='nuclio', filename='functions/stream-to-features.ipynb')\n",
    "project.set_function(stream_to_features)\n",
    "\n",
    "stf_envs = {'FEATURE_TABLE_PATH': feature_table_path,\n",
    "            'SERVING_EVENTS': \",\".join(['bet','win']),\n",
    "            'FEATURE_LIST': \",\".join(feature_list),\n",
    "            'CONTAINER': container,\n",
    "            'OUTPUT_STREAM_PATH': stream_configs['serving-stream']['path'],\n",
    "            'PARTITION_ATTR': partition_attr,\n",
    "            'ENRICHMENT_TABLE_PATH': enrichment_table_path,\n",
    "            'ENRICHMENT_KEY':\"postcode\"}\n",
    "\n",
    "project.func('stream-to-features').set_envs({**v3io_envs, **stf_envs})\n",
    "\n",
    "incoming_events_stream = '/'.join(s.strip('/') for s in [web_api_users, stream_configs['incoming-events-stream']['path']]) + '@stf'\n",
    "project.func('stream-to-features').add_trigger('serving_stream',\n",
    "                                               nuclio.triggers.V3IOStreamTrigger(url=incoming_events_stream,\n",
    "                                                                                 maxWorkers=stream_configs['incoming-events-stream']['shard_count']+2,\n",
    "                                                                                 seekTo='earliest'))\n",
    "\n",
    "project.func('stream-to-features').spec.readiness_timeout = 200\n",
    "project.func('stream-to-features').spec.replicas=1\n",
    "project.func('stream-to-features').deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data Snapshot (part of optional model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_training:\n",
    "    get_data_snapshot = code_to_function(name='get-data-snapshot', handler='snapshot_data', kind='job', filename='functions/get-data-snapshot.ipynb')\n",
    "    project.set_function(get_data_snapshot)\n",
    "\n",
    "    # set parameters and  environment variables\n",
    "    v3io_envs = {'V3IO_API': getenv('V3IO_API'),\n",
    "            'V3IO_ACCESS_KEY': getenv('V3IO_ACCESS_KEY')}\n",
    "    gds_params = {'container': container, \n",
    "                  'table_path': feature_table_path, \n",
    "                  'columns': ['label']+feature_list, \n",
    "                  'format': 'csv'}\n",
    "\n",
    "    project.func('get-data-snapshot').set_envs(v3io_envs)\n",
    "    project.func('get-data-snapshot').apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_training:\n",
    "    project.func('get-data-snapshot').deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_training:\n",
    "    snapshot_data_run = project.func('get-data-snapshot').run(params=gds_params, artifact_path=project.artifact_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the Dataset (part of optional model training)\n",
    "-------------------\n",
    "You can review the plots under - artifacts/plots/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_training:\n",
    "    project.set_function('hub://describe', 'describe')\n",
    "\n",
    "    project.func('describe').apply(mount_v3io())\n",
    "    describe_run = project.func('describe').run(params={'label_column': 'label'},\n",
    "                                inputs={\"table\":\n",
    "                                        snapshot_data_run.outputs['snapshot_dataset']},\n",
    "                                artifact_path=project.artifact_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training (part of optional model training)\n",
    "---------------------\n",
    "function's source and full docstrings can be found at https://github.com/mlrun/functions/tree/master/sklearn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_training:\n",
    "    project.set_function('hub://sklearn_classifier', 'train')\n",
    "    project.func('train').apply(mount_v3io())\n",
    "    \n",
    "    # Configure the models to train\n",
    "    models = [\"sklearn.ensemble.RandomForestClassifier\", \n",
    "              \"sklearn.linear_model.LogisticRegression\",\n",
    "              \"sklearn.ensemble.AdaBoostClassifier\"]\n",
    "    \n",
    "    # Create a training task\n",
    "    train_task = NewTask(name=\"train\",\n",
    "                         params={\"sample\": -1,\n",
    "                                 \"label_column\": \"label\",\n",
    "                                 \"test_size\": 0.10},\n",
    "                         inputs={\"dataset\": snapshot_data_run.outputs['snapshot_dataset']})\n",
    "    \n",
    "    # Run the training task\n",
    "    train_run = project.func('train').run(train_task.with_hyper_params({'model_pkg_class': models},\n",
    "                                                                        selector='max.accuracy'),\n",
    "                                                                        artifact_path=project.artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_training:\n",
    "    # Display the name of the selected model\n",
    "    from IPython.display import display, HTML\n",
    "\n",
    "    display(HTML(f'<b>Best model:</b> '\n",
    "                 f'{models[train_run.outputs[\"best_iteration\"]-1]}'))\n",
    "\n",
    "    # Display the accuracy for the optimal run iteration\n",
    "    display(HTML(f'<b>Accuracy:</b> {train_run.outputs[\"accuracy\"]}'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing (part of optional model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_training:\n",
    "    project.set_function('hub://test_classifier', 'test')\n",
    "    project.func('test').apply(mount_v3io())\n",
    "    \n",
    "    test_task = NewTask(name=\"test\",\n",
    "                        params={\"label_column\": \"label\",\n",
    "                                \"plots_dest\": path.join(\"plots\", \"test\")},\n",
    "                        inputs={\"models_path\": train_run.outputs['model'],\n",
    "                                \"test_set\": train_run.outputs['test_set']}\n",
    "                        )\n",
    "    test_run = project.func('test').run(test_task,\n",
    "                        artifact_path=project.artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_training:\n",
    "    # Display the model accuracy\n",
    "    display(HTML(f'<b>Test Accuracy:</b> {test_run.outputs[\"accuracy\"]}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_function('hub://model_server:development', 'serving')\n",
    "\n",
    "serving = project.func('serving').apply(mount_v3io())\n",
    "if 'train_run' in locals() and train_run.outputs.get('model') is not None:\n",
    "    serving.add_model('my_model', train_run.outputs.get('model'))\n",
    "else:\n",
    "    serving.add_model('my_model', path.join(getcwd(), 'assets/model.pkl'))\n",
    "        \n",
    "serving.set_envs({'INFERENCE_STREAM' : path.join(container, stream_configs['inference-stream']['path']) })\n",
    "\n",
    "serving_stream = '/'.join(s.strip('/') for s in [web_api_users, stream_configs['serving-stream']['path']]) + '@ms'\n",
    "serving.add_trigger('serving_stream',\n",
    "                    nuclio.triggers.V3IOStreamTrigger(url=serving_stream,\n",
    "                                                      maxWorkers=stream_configs['serving-stream']['shard_count']+2,\n",
    "                                                      seekTo='earliest'))\n",
    "serving.spec.config.pop('spec.triggers.http')\n",
    "serving.spec.readiness_timeout = 200\n",
    "serving.spec.replicas = 1\n",
    "\n",
    "serving.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the same event-handler function for logging the inference stream to parquet.\n",
    "inference_logger = code_to_function(name='inference-logger', handler='handler', kind='nuclio', filename='functions/event-handler.ipynb')\n",
    "project.set_function(inference_logger)\n",
    "\n",
    "il_envs = {'PARQUET_SINK_FLAG': 'true',\n",
    "           'STREAM_SINK_FLAG': 'false',\n",
    "           'PARQUET_TARGET_PATH' : inference_parquet_target_path,\n",
    "           'PARQUET_BATCH_SIZE': 8192,\n",
    "           'TS_KEY': 'when',\n",
    "           'TS_FORMAT': '%Y-%m-%d %H:%M:%S.%f',\n",
    "           'FEATURES': \",\".join(feature_list),\n",
    "           'PREDICTIONS': 'about_to_churn',\n",
    "           'CONTAINER': container}\n",
    "project.func('inference-logger').set_envs({**v3io_envs, **il_envs})\n",
    "\n",
    "project.func('inference-logger').apply(mount_v3io())\n",
    "\n",
    "inference_stream = '/'.join(s.strip('/') for s in [web_api_users, stream_configs['inference-stream']['path']]) + '@il'\n",
    "project.func('inference-logger').add_trigger('inference_stream',\n",
    "                                               nuclio.triggers.V3IOStreamTrigger(url=inference_stream,\n",
    "                                                                                 maxWorkers=stream_configs['inference-stream']['shard_count']+2,\n",
    "                                                                                 seekTo='earliest'))\n",
    "project.func('inference-logger').spec.replicas=1\n",
    "project.func('inference-logger').deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
